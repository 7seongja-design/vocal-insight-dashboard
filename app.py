import streamlit as st
import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import io

# Page Configuration
st.set_page_config(
    page_title="Vocal Insight Dashboard PRO",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    h1 {
        text-align: center;
        color: #1DB954; 
    }
    .stAudio {
        width: 100%;
    }
    .metric-card {
        background-color: #282828;
        padding: 1rem;
        border-radius: 0.5rem;
        text-align: center;
    }
    /* Highlight the insight box */
    .insight-box {
        border: 1px solid #1DB954;
        padding: 15px;
        border-radius: 10px;
        background-color: #121212;
        color: #FFFFFF;
    }
</style>
""", unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.title("By Jaemin Lee")
    st.image("https://img.icons8.com/fluency/96/microphone.png", width=80) 
    st.markdown("---")
    st.header("Upload Audio")
    st.info("Supported formats: WAV, MP3")

# Main Content
st.title("ğŸ¤ Vocal Insight Dashboard PRO")
st.markdown("### Advanced Audio Analytics for Vocal Performance")

# File Uploader
uploaded_file = st.sidebar.file_uploader("Choose a vocal file", type=["mp3", "wav"])

if uploaded_file is not None:
    # Loading State
    with st.spinner('Analyzing audio file... performing deep feature extraction.'):
        try:
            # Load Audio
            y, sr = librosa.load(uploaded_file, sr=None)
            duration = librosa.get_duration(y=y, sr=sr)
            
            # --- 1. Basic Info Row ---
            st.markdown("#### ğŸ§ Basic Information")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Sample Rate", f"{sr} Hz")
            with col2:
                st.metric("Duration", f"{duration:.2f} s")
            with col3:
                st.metric("Channels", "Mono" if y.ndim == 1 else "Stereo") 
            
            st.audio(uploaded_file)
            st.divider()

            # --- 2. Advanced Metrics Calculation ---
            
            # A. Dynamic Range: Difference between Peak dB and Mean RMS dB
            rms = librosa.feature.rms(y=y)
            db_rms = librosa.amplitude_to_db(rms, ref=np.max)
            peak_db = np.max(db_rms)
            mean_db = np.mean(db_rms)
            dynamic_range = peak_db - mean_db # Approximate dynamic range
            
            # B. Spectral Centroid (Brightness)
            centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            avg_centroid = np.mean(centroids)
            max_centroid = np.max(centroids) # Peak brightness
            
            # C. Pitch Stability (Chroma Confidence)
            # Use chroma_stft. Calculate the max value per frame (how "certain" are we about the note?). 
            # Mean of these max values = Stability Score.
            chroma = librosa.feature.chroma_stft(y=y, sr=sr)
            pitch_confidence_per_frame = np.max(chroma, axis=0)
            avg_pitch_stability = np.mean(pitch_confidence_per_frame) * 100 # Convert to 0-100 scale
            
            # D. Spectral Flatness (Noise/Breathiness)
            flatness = librosa.feature.spectral_flatness(y=y)[0]
            avg_flatness = np.mean(flatness)
            
            # --- 3. Vocal Data Insight Section ---
            st.subheader("ğŸ“Š Vocal Data Insight")
            
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("Dynamic Range", f"{abs(dynamic_range):.1f} dB", help="Expression range (Peak - Average Volume)")
            m2.metric("Brightness (Centroid)", f"{int(avg_centroid)} Hz", help="Average frequency center. Higher = Brighter")
            m3.metric("Pitch Stability", f"{avg_pitch_stability:.1f}/100", help="Tonal clarity score (0-100)")
            m4.metric("Noise Factor", f"{avg_flatness:.4f}", help="Spectral Flatness (0=Tone, 1=Noise)")

            # Data-Driven Text Feedback
            insight_text = ""
            
            # Dynamic Range Logic
            if abs(dynamic_range) > 15:
                insight_text += f"<li><b>ë‹¤ì´ë‚´ë¯¹ í‘œí˜„ë ¥ (Dynamic Representation)</b>: ìš°ìˆ˜í•©ë‹ˆë‹¤. ë‹¤ì´ë‚´ë¯¹ ë ˆì¸ì§€ê°€ <b>{abs(dynamic_range):.1f} dB</b>ë¡œ ì¸¡ì •ë˜ì—ˆìœ¼ë©°, ë¶€ë“œëŸ¬ìš´ ì†ì‚­ì„ë¶€í„° íŒŒì›Œí’€í•œ ì„±ëŸ‰ê¹Œì§€ ë„“ì€ ê°ì •ì˜ ìŠ¤í™íŠ¸ëŸ¼ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.</li>"
            else:
                insight_text += f"<li><b>ë‹¤ì´ë‚´ë¯¹ í‘œí˜„ë ¥ (Dynamic Representation)</b>: ì¼ì •í•©ë‹ˆë‹¤. ë‹¤ì´ë‚´ë¯¹ ë ˆì¸ì§€ê°€ <b>{abs(dynamic_range):.1f} dB</b>ë¡œ ì¸¡ì •ë˜ì—ˆìœ¼ë©°, í”ë“¤ë¦¼ ì—†ì´ ê¾¸ì¤€í•˜ê³  ì•ˆì •ì ì¸ ë³¼ë¥¨ ì»¨íŠ¸ë¡¤ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.</li>"

            # Brightness Logic
            if max_centroid > 3000:
                insight_text += f"<li><b>ìŒìƒ‰ ë¶„ì„ (Timbre Analysis)</b>: í´ë¼ì´ë§¥ìŠ¤ êµ¬ê°„ì—ì„œ ì£¼íŒŒìˆ˜ ì¤‘ì‹¬ê°’(Spectral Centroid)ì´ <b>{int(max_centroid)} Hz</b>ì— ë‹¬í•©ë‹ˆë‹¤. ì´ëŠ” <b>ë§¤ìš° ë°ê³  ì‹œì›í•œ ìŒìƒ‰</b>ì„ ë‚˜íƒ€ë‚´ë©°, ë°˜ì£¼ë¥¼ ëš«ê³  ë‚˜ì˜¤ëŠ” ëª…ë£Œí•œ ë³´ì»¬ ì§ˆê°ì„ ì¦ëª…í•©ë‹ˆë‹¤.</li>"
            elif avg_centroid < 1500:
                insight_text += f"<li><b>ìŒìƒ‰ ë¶„ì„ (Timbre Analysis)</b>: ë”°ëœ»í•©ë‹ˆë‹¤. í‰ê·  ì£¼íŒŒìˆ˜ ì¤‘ì‹¬ê°’ì´ <b>{int(avg_centroid)} Hz</b>ë¡œ, ì¤‘í›„í•˜ê³  í’ì„±í•œ ì €ìŒì—­ëŒ€ì˜ ë§¤ë ¥ì´ ë‹ë³´ì´ëŠ” ìŒìƒ‰ì…ë‹ˆë‹¤.</li>"
            else:
                insight_text += f"<li><b>ìŒìƒ‰ ë¶„ì„ (Timbre Analysis)</b>: ê· í˜• ì¡í˜€ ìˆìŠµë‹ˆë‹¤. í‰ê·  ì£¼íŒŒìˆ˜ ì¤‘ì‹¬ê°’ì´ <b>{int(avg_centroid)} Hz</b>ë¡œ, ê³¼í•˜ê²Œ ë°ê±°ë‚˜ ì–´ë‘¡ì§€ ì•Šì€ í¸ì•ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í†¤ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.</li>"

            # Stability Logic
            if avg_pitch_stability > 80:
                insight_text += f"<li><b>ìŒì • ì œì–´ë ¥ (Pitch Control)</b>: ë§¤ìš° ë›°ì–´ë‚œ ì•ˆì •ì„±(<b>{avg_pitch_stability:.1f}/100</b>)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. í¬ë¡œë§ˆ ë¶„ì„ ê²°ê³¼, ìŒì •ì´ í”ë“¤ë¦¼ ì—†ì´ ëª©í‘œ í”¼ì¹˜ì— ì •í™•í•˜ê²Œ ê³ ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.</li>"
            elif avg_pitch_stability < 60:
                insight_text += f"<li><b>ìŒì • ì œì–´ë ¥ (Pitch Control)</b>: ë‹¤ì†Œ ë¶ˆì•ˆì •(<b>{avg_pitch_stability:.1f}/100</b>)í•©ë‹ˆë‹¤. í˜¸í¡ì´ ë¶ˆì•ˆì •í•˜ê±°ë‚˜ ë°”ì´ë¸Œë ˆì´ì…˜ì˜ í­ì´ ë„“ì–´ í”¼ì¹˜ê°€ í”ë“¤ë¦¬ëŠ” êµ¬ê°„ì´ ê°ì§€ë©ë‹ˆë‹¤.</li>"
            else:
                insight_text += f"<li><b>ìŒì • ì œì–´ë ¥ (Pitch Control)</b>: ì¤€ìˆ˜í•©ë‹ˆë‹¤(<b>{avg_pitch_stability:.1f}/100</b>). í›ˆë ¨ëœ ë³´ì»¬ë¦¬ìŠ¤íŠ¸ì˜ íŠ¹ì§•ì¸ ì•ˆì •ì ì¸ í”¼ì¹˜ ìœ ì§€ê°€ ê´€ì°°ë©ë‹ˆë‹¤.</li>"

            st.markdown(f"""
            <div class="insight-box">
                <h4>ğŸ™ï¸ Assistant Analysis</h4>
                <ul>
                {insight_text}
                </ul>
            </div>
            """, unsafe_allow_html=True)
            
            st.divider()
            
            # --- 4. Visualizations ---
            st.subheader("ğŸ“ˆ Detailed Visualizations")
            
            # Waveform
            st.markdown("#### Waveform (Amplitude vs Time)")
            fig_wave, ax_wave = plt.subplots(figsize=(10, 2))
            ax_wave.set_facecolor('#191414')
            fig_wave.patch.set_facecolor('#191414')
            librosa.display.waveshow(y, sr=sr, ax=ax_wave, color='#1DB954', alpha=0.8)
            ax_wave.axis('off') # Cleaner look
            st.pyplot(fig_wave)
            
            col_spec, col_chroma = st.columns(2)
            
            with col_spec:
                st.markdown("#### Spectrogram")
                D = librosa.stft(y)
                S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)
                fig, ax = plt.subplots()
                ax.set_facecolor('#191414')
                fig.patch.set_facecolor('#191414')
                img = librosa.display.specshow(S_db, x_axis='time', y_axis='log', ax=ax, sr=sr, cmap='inferno')
                fig.colorbar(img, ax=ax, format="%+2.f dB")
                ax.set_xlabel("Time", color='white')
                ax.set_ylabel("Hz", color='white')
                ax.tick_params(colors='white')
                st.pyplot(fig)
                
            with col_chroma:
                st.markdown("#### Pitch/Chroma")
                fig, ax = plt.subplots()
                ax.set_facecolor('#191414')
                fig.patch.set_facecolor('#191414')
                img = librosa.display.specshow(chroma, y_axis='chroma', x_axis='time', ax=ax, cmap='coolwarm')
                fig.colorbar(img, ax=ax)
                ax.set_xlabel("Time", color='white')
                ax.set_ylabel("Pitch", color='white')
                ax.tick_params(colors='white')
                st.pyplot(fig)

        except Exception as e:
            st.error(f"Error processing audio file: {e}")

    # Technical Guide Section
    st.divider()
    with st.expander("ğŸ’¡ ë¶„ì„ ì§€í‘œ ì•Œì•„ë³´ê¸° (Technical Guide)"):
        st.markdown("""
        - **Waveform (Amplitude vs Time)**: ì†Œë¦¬ì˜ í¬ê¸° ë³€í™”ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. íŒŒí˜•ì˜ í­ì´ ë„“ì„ìˆ˜ë¡ ì„±ëŸ‰ì´ í’ë¶€í•˜ë©°, ê³¡ì˜ ê°ì •ì„ ì— ë”°ë¥¸ ë‹¤ì´ë‚´ë¯¹(ê°•ì•½ ì¡°ì ˆ)ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - **Spectrogram (Frequency vs Time)**: ì†Œë¦¬ì˜ ì„±ì§ˆ(ìŒìƒ‰)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì„¸ë¡œì¶•ì˜ ì£¼íŒŒìˆ˜ ì—ë„ˆì§€ê°€ ë†’ê³  ë°ì„ìˆ˜ë¡ 'ì‹œì›í•˜ê³  ì¨í•œ' ê³ ìŒ(ë°°ìŒ)ì´ ì˜ í˜•ì„±ëœ ê²ƒì…ë‹ˆë‹¤.
        - **Pitch/Chroma (Note vs Time)**: ì–´ë–¤ ìŒì •ì„ ëƒˆëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤. íŠ¹ì • ìŒê³„ ë¼ì¸ì— ë¹¨ê°„ìƒ‰ ë¸”ë¡ì´ í”ë“¤ë¦¼ ì—†ì´ ê¸¸ê²Œ ìœ ì§€ë ìˆ˜ë¡ ìŒì •ì´ ì •í™•í•˜ê³  ì•ˆì •ì ì„ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
        """)

else:
    # Empty State
    st.container()
    st.markdown("""
    <div style='text-align: center; padding: 50px; background-color: #282828; border-radius: 10px; margin-top: 20px;'>
        <h3>ğŸ‘‹ Welcome to Vocal Insight Dashboard PRO</h3>
        <p>Upload an audio file to receive a <b>Data-Driven Precision Report</b>.</p>
        <p style='color: #888;'>Data Insight Team</p>
    </div>
    """, unsafe_allow_html=True)
